%!TEX root = proyecto.tex

\chapter*{Resumen}
\addcontentsline{toc}{chapter}{Resumen}

En 2020 comenzó una gran pandemia, provocada por el coronavirus (COVID-19), que está marcando la historia de la humanidad, y por un tiempo, paralizó todo el funcionamiento de la misma. Tal es la importancia del COVID-19, que la Organización Mundial de la Salud (OMS) presentó medidas para evitar el contagio entre personas. Entre ellas se encuentra la norma del uso de mascarillas para reducir el riesgo de la exposición de la población al virus. 

Para supervisar el uso correcto de las mascarillas en imágenes de personas, se plantea el uso de técnicas de visión artificial y \textit{machine learning} para la implementación de prototipos capaces de llevar a cabo dicho control en tiempo real. Para ello, se centra el esfuerzo en el estudio de las siguientes técnicas: \textit{Haar-like features}, \textit{Facial Landmarks}, \textit{Mediapipe}, \textit{Transfer Learning}/\textit{Tensorflow}. 

La primera técnica, \textit{Haar-like feature}, proviene de una investigación dirigida por Paul Viola y Michael Jones en el año 2001, centrada en el reconocimiento facial en tiempo real mediante el uso de dichas características y un modelo de \textit{machine learning} llamado Adaboost. Una vez detectada la cara, para identificar el uso de la mascarilla se usa un modelo SVM (\textit{support vector machine}), capaz de realizar regresiones y clasificaciones sobre un conjunto de datos, mediante la detección facial del modelo anterior.

La siguiente técnica, \textit{Facial Landmarks}, se apoya en la anterior (\textit{features}) para poder predecir puntos de interés del rostro humano, como: ojos, nariz y boca. Esto se logra por medio de una técnica llamada HOG (\textit{histogram of gradient}), que se basa en el estudio de la dirección de un punto en la imagen utilizando derivadas, logrando obtener unos datos que posteriormente serán utilizados en la creación de un clasificador SVM, capaz de realizar una detección/predicción en tiempo real. La implementación usada para el prototipo de esta técnica fue desarrollada por \textit{Kazemi} y \textit{Sullivan} en 2014.

Por otro lado, el tercer prototipo se centra en el uso de una de las soluciones implementadas en \textit{Mediapipe}, framework de Python desarrollado por Google para la creación de aplicaciones de visión artificial de forma sencilla y potente, llamada \textit{FaceMesh}. Junto a ella, se ha hecho uso de un modelo pre-entrenado de \textit{Haar-like features} y se ha construido un prototipo capaz de realizar detecciones en tiempo real con gran precisión. La idea de esta técnica es detectar un rostro en la imagen de entrada, obtener la zona donde se encuentra la boca del rostro y aplicar el modelo pre-entrenado para detectar si se encuentra una boca o no.

En último lugar, se implementó un prototipo con la técnica de \textit{Transfer Learning} y Tensorflow, plataforma que ha permitido su desarrollo. La idea consiste en la creación de un modelo personalizado para la detección de mascarillas. Concretamente se realizan un total de tres detecciones: mascarilla, no mascarilla, mal uso de la mascarilla. Para ello, se partirá de un modelo de \textit{Deep Learning}, llamado \textit{SSD-MobileNetV2}, y mediante el uso de \textit{Transfer Learning} se logra crear dicho modelo personalizado. Esta técnica se caracteriza por reusar un modelo ya entrenado para un nuevo problema.

Para terminar, se ha realizado una comparación entre todos los prototipos anteriores para estudiar cual de ellos ofrece el mejor control de la norma presentada por la OMS. Como resultado, no existe un único prototipo capaz de destacar sobre el resto en todos los ámbitos. Cada una de las técnicas empleadas pueden solucionar el problema, destacando al primer prototipo (\textit{haar-like features}) capaz de detectar rostros con mascarilla más lejanos, el tercer prototipo (\textit{Mediapipe}) como el más veloz y el prototipo cuatro (\textit{Tensorflow}) como el más acertado sobre el dataset, con un porcentaje de acierto del 40.27\% para el conjunto de test y un 43.8\% para todo el dataset con un 100\% de detecciones en ambos casos.
