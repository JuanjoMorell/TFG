%!TEX root = proyecto.tex

\chapter*{Extended abstract}
\addcontentsline{toc}{chapter}{Extended abstract}

\vspace{-1.1cm}
The COVID-19 pandemic, also known as the coronavirus pandemic, is an ongoing global pandemic of coronavirus 2019 (SARS-CoV-2) disease that affects all the human population. The World Health Organization (WHO) declared a Public Health Emergency of International Concern regarding COVID-19 on January 30, 2020, and later declared a pandemic on March 11, 2020. This is why the WHO plublished an interim guidance to provide a updated recommendation on mask use in health care and community settings, and during home care for COVID-19 cases \cite{covid19}. This document contains updated evidence and guidance on mask management, virus (SARS-CoV-2) transmission, mask use by the public in areas with community and cluster transmission, mask use during vigorous intensity physical activity, etc. In addition, the WHO advises the use of masks as part of a comprehensive package of prevention and control measures to limit the spread of COVID-19 \cite{oms}. For this reason, this work will propose the use of Computer Vision and Machine Learning techniques for the implementation of prototypes capable of carrying out the visual supervision of correct mask use in real time. The effort will be focused on the study of the following techniques: Haar-like features, Facial Landmarks, Mediapipe, Transfer Learning / Tensorflow.

The first technique, Haar-like features, comes from an investigation directed by Paul Viola and Michael Jones in 2001, focused on real-time facial recognition using these type of features and a Machine Learning model called Adaboost. Moreover, paper \cite{paulViola} describes a machine learning approach for visual object detection which is capable of processing images fast and quite accurately. This research can be divided into three key concepts. The first is a new image representation called \textit{Integral Image}, which allows the features used to be computed faster during the execution of the algorithm. The second is a learning algorithm, based on AdaBoost, which selects a small set of features from a larger set of features and produces efficient classifiers. The third one is a method for combining those classifiers into a cascade architecture, which allows discarding background regions of the input image and spending more computation on promising object-like regions. Therefore, in real-time applications, a detector which use this technique is typicall able to run at 15 frames per seconds.

The first prototype is created by using an SVM (Support Vector Machine) model and an OpenCV face detector based on Haar-like features. This is a supervised learning model with associated learning algorithms that analyze data for classification and regresion analysis, and it is created by detections of the OpenCV's face detector itself, with images of faces with a mask and without it, obtaining a prototype that performs a detection that runs at 15 ms in real time with a good accuracy.

The second technique, Facial Landmarks, is implemented in the Dlib library for Python. It allows the recognition of points of interest on the faces that have been detected in the input image. The process that makes Dlib for this technique can be divided into two main steps: detecting faces within the image, and obtaining those points of interest. This implementation is based on the research of Kazemi and Sullivan in 2014, with the paper \textit{One Millisecond Face Alignment with an Ensemble of Regression Trees} \cite{faceLandmark}. This technique is capable of recognizing the following points of interest in a face: mouth, eyebrows, eyes, nose and chin, thanks to the use of an ensemble of regression trees, that can be used to estimate these points (\textit{facial landmarks}) directly from a sparse subset of pixel intensities.

The first step is to find a face within the input image, using the HOG (Histogram of Oriented Gradients) method. It follows an idea similar to the Haar-like features method, since it is based on the detection of features. The theoretical idea behind HOG is to find the appearance and shape of an object by analyzing the intensity of local gradients, thanks to the fact that these gradients have a greater magnitude in the vicinity of edges or corners. While deploying, it splits the image into small regions, called cells, and a one-dimensional gradient histogram is calculated for each of the pixels in each cell. The second step is to estimate the points of interest accurately and efficiently on the face. It is based on gradient boosting for learning an ensemble of regression trees, in charge of predicting the points of interest. 

Using OpenCV and the Dlib ToolKit, both ideas are implemented using pre-trained models. For facial detection and prediction of points of interest, it will be implemented with the models proposed by Dlib, more specifically the detection based on HOG and the prediction called \textit{shape\_predictor\_68\_face\_landmarks.dat}. The prototype created performs detections at 14.7 ms but with poor accuracy for this task. 

The third prototype is built with the use of Mediapipe, an API created by Google that offers customizable machine learning solutions for live and streaming media.
Google recommends Mediapipe to build prototypes by combining existing perception components, to advance them to polished cross-platform applications, and measure system perfomance and resource consumption on target platforms \cite{mediapipe}. Among the solutions it presents, there is a technique called Face Mesh that estimates 468 points of interest of a face, forming a 3D mesh in real time.

MediaPipe Face Mesh employs machine learning (ML) to infer the 3D surface geometry, requiring only a simple webcam like camera input. Using lightweight model architectures together with GPU acceleration throughout the pipeline, the solution delivers real-time performance critical for live experiences.

The pipeline used in this API consists of two Deep Learning models working at the same time. Its purpose is to perform a detection from an image of the points of interest on a face, and build a 3D face landmark model that approximates its surface by regression on said points. This task is facilitated if the face, where the points of interest must be detected, is clipped, thus making the model focus only on finding the points, increasing the precision of the prediction. Likewise, the cutouts of the faces can be generated from the previous predictions made by the same model, and the prediction is only called again when the presence of the face cannot be detected \cite{faceMesh}. All this is implemented thanks to the \textit{MediaPipe framework}. A pipeline is defined as a directed graph of components where each component is called a Calculator. These calculators are connected by data Streams. Each one represents a time-series of data Packets. So, the calculators and streams define a data-flow graph \cite{mediapipe}.

The prototype has been developed using FaceMesh from the MediaPipe API and a detector based on Haar-like features, such as the one mentioned in the Viola and Jones paper. Therefore, the idea behind this prototype is to obtain the area of the mouth thanks to the use of the solution provided by Mediapipe, and detect if there is a mouth in that area using a Haar-like features model implemented in OpenCV with a pre-trained model. The prototype makes detections at 12.3 ms with good precision and accuracy at short distances. 

The last prototype uses the Transfer Learning technique, and for that reason the use of Tensorflow is necessary. It is an Open Source platform dedicated to machine learning, that allows us to easily compile and deploy ML technology applications. It is based on tensors, multidimensional arrays with a uniform type, like np.arrays in Numpy. In the field of computer vision, it has a large number of pre-trained models capable of performing object detection and image classification quickly and accurately. This resource is called TensorFlow Model Garden, and it is a repository with different model implementations and solutions modeled for Tensorflow. The models are pre-trained using a dataset called COCO 2017. This is a large data set on a large scale for object detection, segmentation, and capture. Among these models, MobileNet stands out, capable of obtaining great performance on mobile devices and computers with little computational power. This has created a rise in popularity for detector implementations on embedded devices, such as the Raspberry Pi, or on ESP32 chips using remote processing.

The goal of this prototype is to use Transfer Learning on the MobileNet model to retrain it for our task. Transfer Learning is a technique in which a pre-trained model is reused for a new problem. Currently its use is becoming popular, since it allows the training of a deep neural network with a small amount of data. In this case, the aim is to use a general object detection model and, applying transfer learning, re-train it for a more specific task but without wasting its previous knowledge. 

The prototype has been built with the use of an SSD-MobileNet model, a combination of an SSD (Single Shot MultiBox Detector) model with another model called MobileNet. This type of model is characterized by the use of a method to detect objects in images using a deep neural network, which generates prediction values about the presence of each object / category in each of the detections, and returns the object with the highest match. The dataset used in Transfer Learning is a combination of datasets composed of images of people with a mask, without it and with the mask incorrectly placed. It consists of a total of 895 images, divided into two groups: train and test. The first group contains the images that are used to train the model and has 745 images. Whereas, the test set is used to validate the trained model, and it has 150 images. Once the images are selected, the labeling process is carried out, using a program created with Python called labelImg. 

To perform Transfer Learning using Tensorflow, the following configuration files need to be created: \textit{LabelMap}, two \textit{TFRecord} files, and \textit{pipeline.config}. This last file contains the main information of the model, both the number of classes that it can detect, the size that the images are resized before treating them, and checkpoints for training. For its creation, the use of Protobuf will be necessary. This is a Google tool focused on transforming the xml files generated by labeling the images in protocol buffers, to serialize the information in a structured and faster way. To carry out the training, we use the code provided after the installation of the Tensorflow Object Detection API, called \textit{model\_main\_tf2}. After training, files called checkpoints are obtained, which contains the model that can be loaded for use in Tensorflow. Once the prototype is created, detections are made in a time of 83.3 ms, making the detections slower than the rest of the prototypes created but being a more scalable project.

Tree metrics are used to compare the prototypes. The first comparison is based on the study of the working range of the prototypes, by measuring distance by the size of the detection that the algorithm implemented in the prototype can perform. The second comparison is based on the measure of the time the algorithm takes to process an input image. For this, the same test will be carried out on all prototypes, and the average time (ms) is calculated after an execution of one minute. Finally, the third comparison will study the percentage of correct classifications for the dataset built in this project. All the experiments have been executed in a PC with Intel i7 processor at 1.3GHz and 8 cores, Intel Iris Plus Graphics GPU, 8 Gb of RAM, and Ubuntu version 18.04.

As a result, there is no single prototype capable of standing out across the board, making it impossible to select an optimal solution to the problem in all cases. All the techniques used in this work can solve it and, depending on where the prototype will be applied, another study would have to be carried out to solve these specific objectives. For example, if we wanted to implement a detector of this type in a mobile device or in an embedded system, it would be preferable a prototype that is fast and light, such as the third prototype (Mediapipe). Whereas, if we have a device with more computing power, it could considered using a slower but more precise prototype such as the first one (Haar-like features) or even training a custom model such as the fourth prototype (Transfer Learning). Therefore, a preliminary study should be carried out on the device where the prototype will be applied to make a final decision.


